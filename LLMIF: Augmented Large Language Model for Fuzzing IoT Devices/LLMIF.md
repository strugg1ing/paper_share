#### S&P 2024 　　　　　　　　港理工＆南邮
---  
## <center>LLMIF: Augmented Large Language Model for Fuzzing IoT Devices
## Abstract
<p style="text-align: justify;">尽管模糊测试在验证网络协议实现的正确性方面非常有效，但现有的物联网协议模糊测试方法仍面临多个限制，包括消息格式混淆、消息依赖关系未解决以及测试用例缺乏评估等问题。这些限制显著削弱了物联网模糊测试工具在漏洞识别方面的能力。在本工作中，我们展示了协议规范包含丰富的协议消息描述，这些描述可用于克服上述限制并指导物联网协议的模糊测试。为实现规范分析的自动化，我们将大语言模型与规范内容相结合，并驱动其执行两个任务（即协议信息提取和设备响应推理）。我们进一步设计并实现了一种模糊测试算法 LLMIF，将大语言模型整合到物联网模糊测试中。最后，我们选择 Zigbee 作为目标协议并进行了全面评估。评估结果显示，LLMIF 成功解决了上述限制。与现有的 Zigbee 模糊测试工具相比，它的协议消息覆盖率和代码覆盖率分别提升了 55.2% 和 53.9%。除了覆盖率的提升外，LLMIF 还在真实的 Zigbee 设备上发现了 11 个漏洞，其中包括 8 个此前未知的漏洞，其中 7 个漏洞未被现有的 Zigbee 模糊测试工具检测到。
</p>

## 1. Introduction
<p style="text-align: justify;">
　　确保物联网协议实现的正确性至关重要，因为这些协议保证了物联网设备的预期功能。在关键基础设施（如医疗、交通和能源）中，物联网设备的故障或崩溃可能会导致灾难性后果【1】。协议实现中的一个错误可能引发一连串难以诊断和纠正的故障【2】。尤其是网络协议模糊测试技术被广泛用于识别协议实现中的漏洞【3】【4】【5】【6】【7】。该技术通过生成定制的消息并将其传输至目标设备，以尝试触发意外行为。由于生成的消息符合协议格式要求，网络协议模糊测试相比于二进制模糊测试更具灵活性【8】【9】。它能够轻松地针对不同的协议实现，而无需考虑源代码的可用性和目标设备的硬件配置。</p>
<p style="text-align: justify;">
　　网络协议模糊测试涵盖了多个不同阶段，即模糊测试种子生成、种子变异、测试用例评估和用例扩充。不幸的是，现有的物联网模糊测试工具在设计范围和有效性上存在某些限制，限制了其设计范围和有效性。(L.1) 消息格式混淆。物联网消息通常具有复杂结构，包括精心设计的报头和负载。在缺乏关于这些消息格式的知识情况下，会出现两个主要问题。首先，模糊测试工具的种子生成仅限于相对较少的消息类型。其次，变异过程可能无效，因为它们通常会生成格式错误的测试用例，或忽视对关键位/字节的变异，而这可能暴露漏洞。(L.2) 消息依赖关系未解决。物联网协议展示了一个庞大的设备状态空间，只有通过精心安排的消息序列才能有效导航。如果不解决这些消息依赖关系，丰富测试用例并创建复杂的消息序列将成为一项艰巨的任务。(L.3) 缺乏测试用例评估。基于执行反馈（例如代码覆盖率）对测试用例进行评估是保留进一步检查的有趣用例的标准方法【11】。如果没有适当的评估策略，模糊测试工具将持续生成低质量的测试用例，从而导致模糊测试效果不佳。</p>
<p style="text-align: justify;">
　　遗憾的是，克服上述障碍来模糊测试物联网设备并非易事。(1) 先前的研究【12】使用机器学习技术从纯文本网络跟踪中推断消息格式。然而，物联网协议中使用的灵活且供应商特定的身份验证方案（例如定制的 Zigbee 链接密钥【13】）使得收集纯文本跟踪数据成为一项挑战。(2) 由于消息格式和设备属性的多样性，物联网协议通常缺乏协议状态机的正式定义。这种缺乏定义使得构建消息依赖关系变得复杂。此外，依赖于网络跟踪分析的现有方法【6】【7】在面对定制的身份验证方案时难以奏效。(3) 由于对保护知识产权和避免暴露漏洞的需求，物联网供应商通常不愿共享设备固件的源代码甚至二进制文件。这种不愿共享阻碍了模糊测试工具收集有价值的反馈信息，如代码覆盖率。</p>
<p style="text-align: justify;">
　　为了克服这些限制，我们提出了一个关键的观察：协议规范提供了丰富的消息描述，可以用于指导模糊测试过程。首先，鉴于这些描述包括了消息报头和负载格式的介绍性细节，可以提取这些信息以增强消息覆盖率并构建有效的变异操作符。其次，这些描述往往通过设备属性的相互作用微妙地描绘出消息依赖关系。例如，Zigbee 的 Identify 消息的描述为“这将启动设备的识别过程”，而 AddGroupIfIdentifying 消息的描述为“该消息允许设备在识别自身的条件下添加一个组”，暗示了这两个消息在设备的识别状态下存在关联。最后，这些描述概述了消息处理和响应生成的工作流程，可用于评估测试用例。给定一个传输的测试用例及随后的响应，可以利用这些描述来判断消息执行是否符合规范，导致合法的设备状态转换，或者是否违反规范，导致未定义的设备状态转换。触发设备状态转换的测试用例将被保留，作为后续模糊测试轮次中的新种子。</p>
<p style="text-align: justify;">
　　利用规范来指导物联网模糊测试需要具备文本总结和推理能力。尽管这些任务对人类而言相对简单，但却费时费力且易出错。例如，总结 Zigbee 的 1,213 页文档中指定的 140 多种消息类型格式可能会耗费数天的人力。受大语言模型（LLM）在各种自然语言处理任务中取得的最新进展的启发，我们提出将规范内容扩充至 LLM，并引导其回答协议相关问题。生成的回答随后用于支持模糊测试的各个阶段。我们选择 Zigbee【14】作为我们的目标物联网协议，因为该协议已在全球近 3 亿个节点中实现。具体而言，我们首先应用 LLM 扩充方法，将规范内容注入 LLM。随后，扩充后的 LLM 被分配两个任务：协议信息提取和设备响应推理。对于协议信息提取任务，LLM 被要求从规范中提取有用的协议信息，例如消息格式、重要字段值、报头结构和消息依赖关系。此方法解决了限制 L.1 和 L.2。对于设备响应推理任务，给定生成的测试用例及设备响应，LLM 利用消息描述判断该测试用例是否促成设备状态转换。结果随后用于评估测试用例，从而解决限制 L.3。</p>
<p style="text-align: justify;">
　　最后，我们提出了一种模糊测试算法 LLMIF，将 LLM 集成到 Zigbee 模糊测试中。在每轮模糊测试中，LLMIF 首先利用 LLM 提取的信息（消息负载格式、重要字段值和报头结构）生成种子并执行变异。然后，它将生成的测试用例传输到目标设备，监控设备崩溃并等待设备响应。在收集到的响应中，LLMIF 进一步指示扩充后的 LLM 评估测试用例的质量。对于那些促进设备状态转换的用例，LLMIF 会根据提取的消息依赖关系丰富它们，以构建新的种子，并优先在后续的模糊测试轮次中使用这些种子。
</p>
<p style="text-align: justify;">
　　
我们的评估结果展示了 LLMIF 在代码覆盖率和漏洞识别方面的有效性。与基线相比，LLMIF 将消息覆盖率提高了 55.2%，代码覆盖率提高53.9%。此外，LLMIF 在发现 Zigbee 协议实现中的关键漏洞方面表现出色。我们测试了 11 个实际 Zigbee 设备，并成功识别出 8 个零日漏洞，其中 7 个被现有模糊测试工具忽略。总之，我们的工作做出以下贡献：

* 我们利用扩展的大语言模型（LLM）来分析协议规范，克服了物联网模糊测试的限制，即未知的消息格式、未解决的消息依赖关系和缺乏测试用例评估。
* 我们将扩展的 LLM 集成到 Zigbee 模糊测试中，并提出了模糊测试算法 LLMIF。该算法利用 LLM 的结果来增强模糊测试的各个阶段，包括种子生成、变异、测试用例评估和测试用例扩展。我们还实现了一个用于实际 Zigbee 设备模糊测试的原型【15】。
* 我们进行了实验，展示了 LLMIF 的有效性。与基线相比，LLMIF 更有效地提高了消息类型和协议实现代码的覆盖率。除了覆盖率的提升外，LLMIF 还在现成的 Zigbee 设备中发现了 11 个漏洞，其中包括 8 个零日漏洞，大部分被现有模糊测试工具忽略。

</p>

## 2. Backgrond
<p style="text-align: justify;">
　　在本节中，我们首先介绍 Zigbee 中的主要概念，然后提供一些大型语言模型的背景知识。
</p>

##### Zigbee Protocol

<p style="text-align: justify;">
　　Zigbee 是一种通信协议，旨在为物联网设备提供低功耗、低成本的无线网状网络，并规范了一系列设备功能，例如照明和锁定。为了在 Zigbee 生态系统中提供无缝的通信，Zigbee 联盟在协议规范中提供了“集群”这一概念【16】，它定义了一组设备可以遵循的通用消息格式和数据结构。例如，Zigbee 规定了一个“组”集群（集群ID 0x0004），允许设备被分配到一个或多个组，并支持对多个设备的同时控制。该集群定义了几个设备属性，例如组表，设备应该支持这些属性以指定当前的分组状态。此外，该集群定义了六种具有固定负载格式的消息类型用于通信。例如，表 1 显示了“如果正在识别则添加组”消息（命令 ID 0x05）的格式，如果设备当前处于识别状态，则可以添加消息负载中指定的组。任何违反格式的消息，例如缺少字段或字段值无效，将被视为格式错误的命令，并在目标设备中被过滤而不进行进一步处理。
</p>
<center> 

![alt text](image.png)

</center>
<p style="text-align: justify;">
　　由于覆盖了广泛的设备功能，Zigbee 指定了大量的消息格式。例如，Zigbee 规定了 22 个标准集群，涵盖了超过 140 种消息类型。除了数量庞大的消息外，这些消息还通过通用设备属性相互交织，即消息执行的前提依赖于设备属性的特定设置，而这些设置又由其他消息的执行更新。因此，它们形成了各种消息依赖关系。例如，“查看组成员资格”消息的执行依赖于“添加组”消息的执行，因为其执行需要依赖“添加组”消息来正确设置组表中条目。
</p>

##### 大型语言模型
<p style="text-align: justify;">
　　
大型语言模型（LLMs）是一种可以处理和生成自然语言文本的机器学习模型。它们的基本原理是通过大量的文本数据进行训练，以执行统计语言建模和词预测。特别是，LLMs 在文本摘要、文本推理和上下文对话方面表现出色。例如，最近的一项研究【17】显示，LLM 生成的摘要比文档中的参考摘要更受人类标注者的青睐。研究【18】表明，LLMs 在理解给定文档（例如放射学报告和医患对话）方面表现良好，并能够运用领域知识进行推理。最后，研究【19】显示，LLMs 有潜力理解对话的历史，并生成与之前对话内容相关且连贯的回应。
<p style="text-align: justify;">
　　
LLMs 的一个优势是它们能够快速适应特定任务，例如心理健康分类【20】、问答【21】和渗透测试【22】。为了实现这一目标，通常采用提示工程（prompt engineering）【23】。在提示范式中，预训练的 LLM 会接收一段文本作为输入，并期望提供相关的输出作为响应。提示工程旨在提供一套原则和技术，用于设计提示，以充分发挥这些机器学习模型的最佳性能。
</p>
<p style="text-align: justify;">
　　
尽管 LLMs 作为通用任务求解器具有很大的潜力，但最近的研究【24】表明，它们存在一些重要的局限性，阻碍了更广泛的应用。第一个限制是它们缺乏特定领域的知识，使其在执行领域特定任务时表现不足。第二个限制是它们通常提供非事实但似乎合理的预测，这种现象被称为“幻觉”【25】。因此，越来越多的研究趋势出现，旨在通过引入领域知识来增强 LLM，以解决上述限制，这被称为“增强语言模型”（Augmented Language Models, ALM）。
</p>

## 3. LLM Augmentation with Specification LLM （增强与规范）
<p style="text-align: justify;">
　　在本节中，我们将讨论增强 LLM for IoT 模糊测试的方法。我们首先表明 LLM 缺乏对 IoT 协议的理解，这突出了将其注入领域知识（即规范内容）的必要性。然后我们详细介绍我们的增强方法。</p>

##### LLM 对 Zigbee 的理解
<p style="text-align: justify;">
　　预训练于海量互联网数据的大型语言模型（LLM）已经吸收了来自不同领域的知识。它们在各种任务中表现出了有效性，尤其是在问答任务方面。受到最近研究的启发，该研究利用LLM的内部知识来指导网络协议模糊测试，例如RTSP，我们对一个问题产生了好奇：LLM是否对物联网协议（如Zigbee）有足够的理解，以便能够输出有用的协议信息来指导模糊测试过程？
</p>
<p style="text-align: justify;">
　　为了解答上述问题，我们启动了一个案例研究。具体来说，我们选择了四个流行的LLM作为目标：OpenAI的ChatGPT、Meta的LLaMA 2、Google的PaLM和Anthropic的Claude。得益于数十亿的模型参数，这些LLM被广泛使用并在各种任务中表现出色。我们要求它们克服现有Zigbee模糊测试器的局限性，并构建Zigbee消息有效载荷格式。我们从22个标准Zigbee集群中选择了96种消息类型以构建基准，每种消息都至少包含一个字段。我们指定了两个子任务来评估LLM的性能。（1）消息识别：LLM应该输出正确的消息名称。（2）格式推断：LLM应该为每条消息输出正确的字段名称和字段数据类型。只有在正确识别名称并正确推断格式的情况下，消息格式才能成功构建。</p>
<p style="text-align: justify;">
　　图 1a 和图 1b 显示了评估结果。在 96 种消息类型中，这些 LLM 平均只成功构建了 15 种消息格式，实现了 15.6% 的低召回率。因此，如果 LLM 直接用于指导模糊测试过程，则模糊测试程序将实现较低的消息覆盖率，并忽略隐藏在这些缺失消息的处理逻辑中的关键错误。上述结果表明，LLM 对 IoT 协议的理解不够，在执行协议模糊测试之前，有必要用领域知识（即协议规范）来增强它。我们还在补充材料 [15] 中提供了一个演示以供参考。</p>

<center> 

![alt text](image-1.png)

</center> 

##### 增强方法
<p style="text-align: justify;">
　　大型语言模型（LLM）增强的常见范式遵循“检索-然后-阅读”管道。首先，由于LLM的上下文大小有限，需要一个知识检索器从外部知识源（例如维基百科页面）中检索与任务相关的知识。其次，将检索到的知识输入到LLM中，以使其适应下游任务，例如问答。在本研究中，我们的目标是从规范中检索消息描述作为领域知识，并将其注入到LLM中。
</p>
<p style="text-align: justify;">
　　与之前的研究不同，这些研究需要大量的训练数据并训练神经检索器，我们的观察是，规范文档通常以良好格式的文件形式组织，例如PDF，这些文档记录了丰富的元数据以供知识索引和搜索。特别是，文档大纲记录了语义上有意义的标题，例如“3.5.2.3 接收的命令”，这可以帮助定位包含消息描述的相应部分。给定规范文档后，我们首先对其进行解析并构建大纲的层次结构。层次结构中的每个条目对应于一个部分，记录了部分级别、部分名称和所涵盖的页面。然后，我们使用正则表达式匹配部分名称包含关键字“接收的命令”的条目。对于所有匹配的条目，我们进一步跟踪其子条目，每个子条目表示讨论特定集群消息的子部分，例如“3.5.2.3.1 识别命令”。因此，我们使用这些子部分所覆盖的页面内容来构建相应消息的领域知识。我们为147个集群消息识别了271页和596,140个字符。
</p>
<p style="text-align: justify;">
　　为了将提取的领域知识增强LLM以进行下游任务，例如提取消息有效载荷格式，我们进一步采用背景增强提示技术，该技术利用领域知识构建特定任务的提示。具体来说，给定检索到的消息描述c和下游任务指令q，例如“总结添加组消息格式”，我们将c和q连接起来构建提示，以驱动LLM基于规范内容构建消息格式。与微调技术相比，背景增强提示方法避免了显著的调整成本。此外，考虑到并非所有LLM都是开源的并且支持微调，提示技术更为通用，可以与任何LLM配合使用。
</p>    

## 4. LLM-Guided IoT Fuzzing
<p style="text-align: justify;">
　　通过增强的LLM，我们开发了一个LLM引导的模糊测试算法LLMIF，以应对现有模糊测试器的局限性。图2展示了工作流程。LLMIF的输入是规范文档，输出是导致目标设备崩溃的测试用例。具体来说，(1) LLMIF首先使用增强的LLM（第3节）分析规范并提取四种类型的协议信息：消息有效载荷格式、有趣的字段值、消息头结构和消息依赖关系。提取过程在模糊测试过程开始之前仅执行一次，因此提取的信息可以直接在后续的模糊测试阶段中使用，而无需与LLM进行通信。接下来，LLMIF开始并循环进行模糊测试轮次（步骤2-5）。(2) 在每轮中，LLMIF首先确定种子。它检查是否有在先前轮次中增强的测试用例。如果有，LLMIF将选择其中一个作为种子。否则，LLMIF利用提取的头结构、有效载荷格式和有趣的字段值从头生成一个消息作为测试用例。(3) 确定种子后，LLMIF进一步突变种子并生成测试用例。突变阶段还利用提取的信息来突变头部和有效载荷中的字段。生成的测试用例进一步传送到目标设备进行执行。(4) LLMIF设置超时并等待设备响应。如果在未收集到响应的情况下超时到达，LLMIF将重复发送三次。如果仍然没有响应，则认为目标设备崩溃，并记录测试用例。否则，LLMIF实时利用增强的LLM分析响应。那些促进设备状态转换的测试用例将被记录。(5) 最后，LLMIF通过附加遵循消息依赖关系的新消息来丰富记录的测试用例。LLMIF进一步优先考虑在后续轮次中使用它们作为种子。在接下来的章节中，我们将详细讨论每个模块的设计。</p>  

<center> 

![alt text](image-2.png)
</center> 

##### 协议信息提取
<p style="text-align: justify;">
　　通过增强的LLM，LLMIF采用背景增强提示技术（第3.2节）来提取四种类型的协议信息：消息有效载荷格式、有趣的字段值、消息头结构和消息依赖关系。</p> 
<p style="text-align: justify;">
　　<b>消息有效载荷格式</b>。图3a展示了用于提取消息格式的提示模板。该模板有两个插槽：“消息名称”和“消息描述”，用于编码检索到的消息描述。请注意，消息描述可能跨越多个页面，并且大小可能超过LLM的上下文限制。因此，我们提出了一种总结方法，以生成简洁的消息描述以构建提示。具体而言，给定一个从页面m到页面n的消息描述（m ≤ n），我们首先要求LLM总结每个页面i上记录的消息格式的信息。然后，我们将每个页面的摘要汇总为最终的消息描述，并将其编码到最终提示中。为了指导LLM生成结构良好的答案以便进一步解析，我们采用了少样本学习技术[37]，引导LLM生成JSON表示，其中键是消息名称，值是字段信息（字段名称：字段数据类型）。我们构建了147个模型提示，每个提示针对特定的集群消息，并使用chatGPT-3.5-turbo作为LLM来构建它们的格式。然后，我们评估了96条消息的构建准确性，这些消息的有效载荷至少包含一个字段。结果表明，增强的LLM成功构建了所有集群消息的格式。</p> 


<center> 

![alt text](image-3.png)

</center> 

<p style="text-align: justify;">
　　<b>有趣的字段值</b>。除了有效载荷格式外，我们还发现消息描述记录了大量有趣的字段值。特别地，我们从规范中对有相关进行了两类分类：(1) 危险值。这些值是规范禁止用于设置字段的。例如，规范要求“添加组”消息中的GroupID字段应在0x0001至0xfff7之间。范围外的值，例如0x0000，是无效的，不应用于设置该字段。(2) 功能值。这些值用于触发特定的设备功能逻辑。例如，图4显示，当“带效果关闭”消息的EffectVariant字段值为0x02时，目标设备应在0.8秒内将亮度降低50%。由于这些有相关可以帮助生成探索不同设备功能和错误处理逻辑的初始种子，我们使用增强的LLM收集它们。结果，我们构建了96个提示，增强的LLM成功收集了68个消息字段的421个功能值。此外，它还收集了与69个消息字段相关的83个危险值区间。</p>

<center> 

![alt text](image-4.png)

</center>

<p style="text-align: justify;">
　　<b>消息头结构</b>。消息头包含重要字段，这些字段对变异非常有价值。因此，基于消息头的描述，我们驱动LLM绘制消息头的结构。结果，它成功提取了头部的七个字段。其中一个重要字段是“禁用默认响应”位字段。当接收到一条消息时，Zigbee设备将检查此位以确定是否应生成响应。通过变异此位，模糊测试工具可以请求目标设备对接收到的测试用例生成响应，而该响应反过来可以作为反馈来评估测试用例的质量（第4.4节）。</p>
<p style="text-align: justify;">
　　<b>消息依赖关系</b>。如第2.1节所述，Zigbee消息通过共同的设备属性彼此隐式关联。也就是说，如果消息A的执行更新了消息B在执行前检查的一些设备属性，则消息A和B之间存在依赖关系（A → B）。由于消息描述通常详细说明了消息与设备属性的交互方式，增强的LLM应该能够推理两个消息之间是否存在依赖关系。图3b展示了用于构建消息依赖关系的模型提示模板。该模板以两个消息的描述作为输入以构建领域知识。与之前要求LLM进行文本摘要的任务不同，消息依赖关系的构建需要激活LLM的推理能力。也就是说，LLM应首先理解两个消息各自与之交互的设备属性，然后确定它们是否在同一属性上工作。因此，我们采用了链式思维技术[38]来引导LLM逐步思考。通过该提示模板，我们构建了21,609个提示，每个提示用于检查特定的消息对。结果，增强的LLM成功构建了147个集群消息之间的968个消息依赖关系。</p>

##### 种子生成
<p style="text-align: justify;">
　　LLMIF 进一步利用提取的消息信息来促进种子生成，如图 5 所示。具体而言，对于每个构建的消息格式，LLMIF 为其分配一个唯一的消息标识符:

$$
\text{MID} = (\text{clusterID}, \text{cmdID}) 
$$

</p>
<p style="text-align: justify;">
其中 clusterID 标识消息的集群，而 cmdID 在集群的消息集中标识该消息。此外，LLMIF 使用消息格式构建一组消息模板，并维护从 MID 到模板的映射：

$$
\{\text{MID} \rightarrow \{(\text{field name}_i, \text{field type}_i, \text{field value}_i)\} \}
$$
</p>
<p style="text-align: justify;">
其中 𝑖 是对应字段的索引。模板中的字段值槽标记了需要填充详细值的区域，以生成格式良好的消息。类似地，LLMIF 还维护了从 MID 到提取的有相关的映射：

$$
\text{MID} \rightarrow \{(\text{field name}_i, \{\text{value interval}_j\})\}
$$
</p>

<p style="text-align: justify;">
其中 𝑖索引字段，𝑗 索引该字段的记录的相关值区间。在每个模糊测试轮次中，首先随机选择一个 MID，例如 (0𝑥0004,0𝑥00)，表示来自 Groups 集群的“添加组”消息。然后，LLMIF 检索相应的消息模板并识别需要填充的槽。例如，“添加组”消息的模板包含两个字段槽需要填充，字段类型分别为 uint16 和 string。为了确定具体的字段值，模糊测试器首先使用 MID 和字段名称作为关键字查找相关值。如果该字段有任何记录的值区间，LLMIF 随机选择一个区间并抽样一个值作为填充槽的具体值。否则，LLMIF 根据数据类型随机生成具体值。例如，在检查到 GroupID 字段有两个相关值区间后，LLMIF 随机选择区间[0𝑥0000,0𝑥0001)并抽值 0
𝑥0000作为 GroupID 字段的值。至于没有记录的相关值的 GroupName 字段，LLMIF 随机生成字符串 “TestGroup” 作为字段值。
</p>
<p style="text-align: justify;">
　　除了设置消息负载外，LLMIF 还利用提取的标头结构来正确设置消息标头。我们在这里讨论三个重要领域。（1） 制造商专用的钻头。此位用于确定当前消息是来自 Zigbee 集群规范还是由制造商创建。由于 LLMIF 主要关注规范中记录的消息，因此该位被设置为零。（2） 方向位。该位用于表示消息是请求消息还是对以前收到的请求的响应。由于在大多数情况下，模糊测试程序充当客户端，将请求传输到目标设备，因此此位设置为零，这表示消息是请求。（3） 禁用默认响应位。如 Section 4.1 中所述，此位对于从目标设备收集响应至关重要。因此，LLMIF 将位设置为零，这要求目标设备始终为收到的每条消息生成响应。</p>

##### 种子变异

<p style="text-align: justify;">
　　为了变异生成的种子，LLMIF 利用提取的协议信息来指定两种类型的变异操作符：类型感知变异和头部感知变异。</p>
<p style="text-align: justify;">
　　<b>类型感知变异</b>。LLMIF 利用每个字段的数据类型知识来执行类型感知变异。具体而言，我们首先总结提取的数据类型并将其分类为两类：固定长度类型和变长类型。前者通常用于数值数据类型，例如 uint32 和 enum16，而后者通常用于字符串类型，例如字符字符串和八位字符串。特别地，变长类型通常具有额外的语法要求。例如，例如，变长类型要求第一个字节表示字符串的长度，后面跟着字符串的内容。</p>
<p style="text-align: justify;">
　　给定一条消息及其格式，模糊测试器遍历每个字段的数据类型并确定相应的变异操作符。对于固定长度类型的字段，LLMIF使用极值操作符进行变异。通过将数值设置为极端值，例如0x0000和0xffff，旨在触发越界漏洞。对于可变长度类型的字段，LLMIF采用以下两种变异操作符：（1）字节扩展。通过增加字符串内容和相应的长度字节，LLMIF旨在触发缓冲区溢出和堆溢出。（2）可疑长度。通过变异可变长度字段的长度字节，LLMIF旨在制造不一致并触发内存泄漏或空指针解引用漏洞。除了上述类型感知的变异操作符，LLMIF还随机移除一些消息字段，并故意创建格式错误的测试用例。如果负载域没有被正确解析，这些案例可能会导致目标设备崩溃。</p>
<p style="text-align: justify;">
　　<b>头部感知变异</b>。LLMIF还利用消息头的结构，并强制实施一组头部感知的变异操作符。（1）构造的命令标识符。LLMIF使用随机生成的值破坏命令标识符字段。（2）位翻转。通过翻转消息头中的特定位，模糊测试器变异帧类型、消息来源和消息方向，旨在测试头部解析过程的正确性并触发意外的消息处理逻辑。请注意，为了确保响应收集，默认响应禁用字段不会被翻转。</p>

##### 响应推理
<p style="text-align: justify;">
　　生成的测试用例将被传输到目标设备进行执行。为了保证每个测试用例执行时的初始状态相同，LLMIF首先传输一条通用的Zigbee消息“恢复出厂设置”（clusterID=0x0，commandID=0x0），以初始化设备状态。在测试用例传输到目标设备并收集到响应后，LLMIF利用增强的LLM对响应进行推理并评估测试用例。这个想法基于两个关键观察结果。（1）目标设备生成的响应通常包含一个状态码，标记测试用例的执行状态。例如，状态码0x00表示最后一条消息已成功执行，而0x80表示最后一条消息格式错误。（2）消息描述详细说明了生成特定状态码的各种情况。例如，当收到具有正常字段值的“添加组”消息时，规范要求“...设备将组ID和组名字段的值添加到其组表中，状态应为SUCCESS...”。另一个例子是，当收到具有危险字段值的“添加组”消息时，规范要求“...设备验证GroupID字段包含范围在0x0001-0xfff7内的有效组标识符。如果GroupID字段包含超出此范围的组标识符，状态应为INVALID VALUE...”。</p>
<p style="text-align: justify;">
　　上述观察表明，结合消息描述，响应可以用于评估测试用例的质量。（1）响应中的状态码可用于检查测试用例是否成功执行并改变了设备状态。例如，如果“添加组”消息收到一个SUCCESS状态码的响应，则意味着设备属性，尤其是组表，已经更新，并且发生了设备状态转换。因此，这类测试用例值得保留以便进一步调查。（2）状态码可用于启动符合性测试，以检测消息执行是否违反规范并使设备进入危险和未指定状态。例如，如果带有GroupID 0x0000的“添加组”消息收到SUCCESS状态码的响应，而根据规范，这应该是INVALID VALUE，则意味着该构造的消息成功污染了组表。由于这些测试用例违反了规范并将设备置于未指定状态，因此它们对于进一步调查也很有价值。</p>
<p style="text-align: justify;">
　　然而，考虑到状态码和消息描述的数量庞大，以及每轮模糊测试生成的测试用例数量极多，几乎不可能让人类参与并推理每个测试用例的响应。为了克服这个挑战，LLMIF利用增强的LLM来执行该任务。模型提示模板如图6所示。它接受三条信息作为输入：消息描述、消息细节和消息执行状态。对于每个测试用例，LLMIF首先检查该用例中的消息，并获取其描述以增强LLM。由于响应推理需要消息的详细信息，例如GroupID值，LLMIF进一步将消息的字段名称和值连接成一个字符串，以构建消息细节。最后，LLMIF从设备响应中提取执行状态码，构建提示，并请求LLM确定设备状态转换是否发生。无论是与规范一致的正常状态转换，还是违反规范的异常状态转换，LLMIF都会记录相应的测试用例以便进一步调查。</p>
<center>

![alt text](image-5.png)
</center>

##### 测试用例增强
<p style="text-align: justify;">
　　一旦测试用例引起了LLM的注意并被LLMIF记录（第4.4节），它将被增强以构建新的种子。对于每个测试用例，我们将其交互的设备属性定义为由最后一条消息更改的属性。因此，在增强测试用例时，我们只考虑依赖于最后一条消息的消息，以便增强后的用例将检查交互的设备属性。</p>

<p style="text-align: justify;">
　　具体而言，给定一个测试用例s = [m1, ..., mn]，其中包含n条消息，测试用例增强的任务是构建一个适合的消息mn+1，可以附加到s的末尾，使得构建的消息序列s′ = [m1, ..., mn, mn+1]中的每对相邻消息都遵循消息依赖关系。</p>
<p style="text-align: justify;">
　　LLMIF利用提取的消息依赖关系来执行该任务。具体而言，依赖关系以消息对的形式存储：

$$
D = \{d : (MIDpre, MIDcon)\}，
$$

其中前一条消息和对应MID表示的后续消息在共同的设备属性上相关。给定一个测试用例s，LLMIF首先获取最后一条消息mn的MID，并寻找与s相关的候选消息集合M，即:
$$
M = \{MID|(m_n.MID, MID) ∈ D\}
$$

确定M后，LLMIF随机从M中选择一个MID，并按照第4.2节初始化消息mn+1，其消息标识符等于MID。最后，测试用例通过新消息增强，即s′ = s + [mn+1]，并将s′保存到种子库中，优先在下一轮模糊测试中选择。</p>

##### 模糊测试工具实现
<p style="text-align: justify;">
　　与模糊测试传统网络协议（例如，SMTP [39]）不同，模糊测试现实世界的Zigbee设备需要特定无线模块（例如，CC2530）的支持。为了对现实世界的Zigbee设备进行模糊测试，我们设计了一种模糊测试工具，包含两个组件：模糊控制器和栈控制器。模糊控制器负责运行LLMIF并组织模糊测试工作流程。具体而言，使用chatGPT-3.5.turbo作为大型语言模型。另一方面，栈控制器作为驱动程序，操作可编程Zigbee无线电，并为Zigbee通信提供基本支持，例如消息传输和接收。
</p>
<p style="text-align: justify;">
　　模糊控制器利用“构建块”的思想来构建消息，这在基于生成的模糊测试中常被使用 [4]，[40]。具体而言，我们实现了Zigbee规范中指定的47种基本数据类型，例如enum8和string，并将它们作为组装消息有效负载的构建块。因此，提取的协议信息，例如消息格式和有趣值库，可以很容易地集成到组装过程中。我们进一步实现了总共七个变异操作符（第4.3节）来执行变异。模糊控制器用Python实现，代码量达到3000行，并在运行Ubuntu 20.04操作系统的Raspberry Pi 4上运行。
</p>
<p style="text-align: justify;">
　　栈控制器的目的是创建并维护与目标设备的Zigbee通信通道。考虑到可用性和普及性，我们选择CC2538作为具有完全合规Zigbee解决方案Z-Stack [41] 的硬件无线电。我们在Z-Stack之上开发了一个驱动程序，将CC2538转变为Zigbee节点。该节点形成一个完全控制的Zigbee网络，允许目标设备加入。一方面，它通过通用异步接收/transmitter（UART）通道与模糊控制器通信，即接收测试用例并转发设备响应。另一方面，它通过透明和经过身份验证的Zigbee网络与目标设备通信，即传输测试用例并监控设备响应。该驱动程序使用1000行C代码开发。
</p>

## 5. 评估
<p style="text-align: justify;">
　　为了评估LLMIF的有效性，我们寻求以下问题的答案。
</p>

* Q1：代码覆盖率。与基线相比，LLMIF能够实现多少额外的代码覆盖率？

* Q2：消融实验。提取的协议知识对LLMIF的性能有何影响？

* Q3：错误识别。LLMIF是否能够发现现实世界设备上以前未知的错误？

<p style="text-align: justify;">
　　在接下来的章节中，将介绍我们的实现和实验设置。最后，我们讨论上述问题的评估结果。</p>

##### 实验设置
<p style="text-align: justify;">
　　<b>用于代码覆盖率评估的Z-Stack仿真</b>。在实验过程中，我们发现评估代码覆盖率具有一定挑战。主要原因是大多数Zigbee设备供应商并未开源其栈实现（无论是源代码还是二进制固件），因此我们无法对栈实现进行插桩以计算语句/边覆盖率，只能进行黑盒模糊测试。我们找到的唯一开源Zigbee栈是德州仪器的Z-Stack [41]。受[4]的启发，我们利用IAR开发工具链并搭建了一个仿真平台，该平台支持栈执行仿真、Zigbee消息传输/接收，最重要的是支持覆盖率分析。</p>
<p style="text-align: justify;">
　　(1) 我们编写了一个栈驱动程序（900行C代码）来构建一个Zigbee终端设备应用程序。栈驱动程序和栈源代码被C-SPY仿真工具使用，使我们能够创建一个模拟的终端设备作为目标设备。我们的驱动程序注册了一组由Z-Stack提供的插件，使该模拟终端设备可以支持22个标准集群中的154条集群消息，相比之下，[4]中的驱动程序仅支持22条消息。</p>
<p style="text-align: justify;">
　　(2) 我们使用共享文件来模拟模糊测试器与模拟目标设备之间的通信通道。通过读写共享文件，模糊测试器和模拟设备分别可以模拟空中Zigbee消息的传输/接收。</p>
<p style="text-align: justify;">
　　(3) 对于生成的测试用例，我们使用IAR工具链提供的代码覆盖分析和静态分析工具来计算语句覆盖率和边覆盖率，具体细节将在第5.2节中详述。</p>
<p style="text-align: justify;">
　　(4) 通过检查仿真工具的输出，我们确定测试用例是否触发模拟设备的异常并导致崩溃。测试用例的处理调用栈用于分类崩溃类型和对崩溃用例进行聚类。此外，崩溃用例将被存储，以便在现实的德州仪器设备上进一步验证（第5.4节）。</p>

<p style="text-align: justify;">
　　<b>真实环境下的Zigbee设备（DUT）</b>。除了对仿真设备进行模糊测试外，我们还从多家厂商中挑选了11款市售Zigbee设备进行评估，涵盖了飞利浦、Third Reality、Sengled、Aqara和Tuya等知名品牌。所选设备类型包括智能开关、插头、灯具、锁具和传感器。这些设备要么是Amazon推荐的产品，要么是超市中的畅销产品。需要注意的是，其中一些设备已被发现存在零日漏洞且尚未修复。因此，我们对这些设备及其型号进行了匿名处理。一旦这些漏洞被厂商修复且披露期限到期，我们承诺解密这些设备的具体信息。</p>

<p style="text-align: justify;">
　　<b>基线方法</b>。我们选择了四个流行的Zigbee模糊测试工具作为基线：BOOFUZZ [42]、Z-FUZZER [4]、BEEHIVE [5]和CHATAFL [6]。这些工具要么在业界广泛应用，要么在顶级安全会议中有所报道。此外，这些工具的设计涵盖了现有解决方案中一些关键的模糊测试任务，尤其是消息格式构建和有趣值收集，使其适合作为我们方法的比较基线。具体而言，BOOFUZZ是一个著名的基于语法的模糊测试工具，经[4]定制后支持Zigbee模糊测试。Z-FUZZER是一个覆盖率引导的Zigbee模糊测试工具，已被用于识别Z-Stack中的关键零日漏洞。BEEHIVE研究集群消息格式，并手动提取一组用于字段值枚举的有趣值。最后，CHATAFL利用大型语言模型（LLM）来指导模糊测试过程，特别是消息格式构建，并已用于模糊测试网络协议（例如RTSP）。虽然其并非专为Zigbee模糊测试设计，但我们使用其提出的提示工程技术并将其扩展，以支持Zigbee消息格式构建和模糊测试。</p>

<p style="text-align: justify;">
　　<b>LLM使用</b>。在实验中，我们使用chatGPT-3.5作为通用的大型语言模型（LLM）。该LLM接受一个超参数，即temperature ∈ [0, 1]，用于调节随机性和创造性。为减轻LLM的“幻觉”问题（即生成答案中高误报的情况），我们将temperature设置为零。基线方法也采用相同的设置。由于chatAFL是基线方法中唯一使用LLM指导的模糊测试工具，这意味着LLMIF和chatAFL将使用相同的通用LLM（在我们的实验中为chatGPT-3.5），并采用相同的temperature设置。因为chatAFL完全依赖LLM的知识库来指导物联网协议的模糊测试，其性能将揭示LLM知识不足（第3.1节）对物联网协议模糊测试的影响。</p>

##### 覆盖率分析
<p style="text-align: justify;">
　　<b>消息覆盖率分析</b>。我们首先评估LLMIF在模糊测试中的消息覆盖率，并与基线方法进行比较。具体而言，我们旨在测量11个设备的簇覆盖率和消息覆盖率。为了建立基准，我们首先向目标设备发送Zigbee设备对象（ZDO）命令，扫描其支持的簇和命令。设备D1是一个加载了Z-Stack的CC2538模块，由于Z-Stack是开源的，我们编译了Z-Stack固件并将其烧录到CC2538模块中，使其支持18个标准簇，包含150种消息类型。对于每个模糊测试工具，我们传输一条基于其理解的消息格式构建的消息，并检查响应状态码来评估其是否覆盖该消息类型。如果目标设备接受该消息并返回SUCCESS状态码，则该消息类型被成功覆盖。否则，返回的错误码（如INVALID FORMAT）表示消息格式不正确且未覆盖该消息。</p>

<p style="text-align: justify;">
　　结果如表2所示。我们的方法成功覆盖了来自18个簇的150种消息类型，实现了100%的簇和消息覆盖率。与基线方法相比，我们的方法将簇覆盖率提高了73.1%，消息覆盖率提高了55.2%。具体而言，Z-FUZZER、BOOFUZZ和BEEHIVE依赖人工构建消息格式，并仅关注基础簇，总共包含22种消息类型。对于CHATAFL，我们进行了10轮消息格式构建，由于缺乏规范指导，LLM仅可靠地构建了Identify、Groups和Scenes簇的15种消息格式。与基线方法相比，我们通过增强的LLM精确构建了所有消息格式。</p>

![alt text](image-6.png)

<p style="text-align: justify;">
　　代码覆盖率分析。我们进一步评估代码覆盖率并与基线方法进行比较。不幸的是，如第5.1节所述，大多数现成的Zigbee设备并未开源其堆栈实现，因此只能进行黑盒测试，无法收集代码覆盖率统计信息。例如，对于来自8个厂商的11个设备，只有德州仪器的Z-Stack是开源的。因此，我们将使用基于Z-Stack构建的模拟终端设备（第5.1节）作为目标设备进行代码覆盖率分析。具体而言，我们使用常用的度量标准语句覆盖率（覆盖的代码行数）和边覆盖率（覆盖的代码分支数）进行比较。我们首先静态分析了15个实现Zigbee簇功能的源文件，以构建基准，如“zcl lighting.c”。总计识别出1,665条边和3,147条语句。然后，对于每个Zigbee模糊测试工具，我们生成20,000个测试用例，计算累计的语句覆盖率和边覆盖率。评估结果如图7a和图7b所示。最后，我们通过计算LLMIF的覆盖率与基线方法中最高覆盖率的差值来获得覆盖率提升。例如，在语句覆盖率方面，基线中表现最好的模糊测试工具（Z-Fuzzer）覆盖了797条语句，而我们的方法覆盖了2,493条语句。覆盖率提升计算为(2493-797)/3147 = 53.9%。消息覆盖率的计算方法相同。</p>

<p style="text-align: justify;">
　　与基线方法相比，LLMIF在边覆盖率方面提高了52.0%，在语句覆盖率方面提高了53.9%，显示了我们方法的优越性。总体而言，低消息覆盖率通常会导致低代码覆盖率。然而，BEEHIVE是一个例外。尽管其支持的消息类型比ZFUZZER多，但其代码覆盖率较低，主要原因在于其变异策略不足。具体来说，BEEHIVE仅对“AttributeID”和“AttributeDataType”这两个字段进行变异，且仅使用了有限数量的有趣值，这限制了其发现更多代码路径的能力。</p>

<p style="text-align: justify;">
　　<b>问题1的回答</b>：实验结果表明，LLMIF在消息覆盖率和代码覆盖率方面优于现有的Zigbee模糊测试工具。与最佳基线模糊测试工具相比，LLMIF在消息覆盖率、边覆盖率和语句覆盖率方面分别提高了55.2%、52.0%和53.9%。</p>

<p style="text-align: justify;">
　　尤其是，与完全依赖通用LLM知识库指导物联网模糊测试的chatAFL相比，LLMIF的消息覆盖率、边覆盖率和语句覆盖率分别提高了82.1%、67.4%和64.1%。这些覆盖率的提升显示了通用LLM在模糊测试物联网协议栈方面的不足，并证明了我们提出的LLM增强方法和模糊测试算法的优势。</p>

##### 消融研究
<p style="text-align: justify;">
　　LLMIF利用增强的LLM提取多种协议信息，以增强模糊测试的不同阶段。为了评估这些提取信息的贡献，我们进行了消融研究，开发了四种LLMIF的变体：</p>

* V1: 仅使用消息格式生成初始测试用例。
* V2: 在V1的基础上，加入“有趣值”知识用于生成初始测试用例。
* V3: 在V2的基础上，加入消息头的知识，用于初始测试用例生成和变异。
* V4: 在V3的基础上，加入消息依赖关系知识，用于初始测试用例生成、变异和相关案例丰富。

<p style="text-align: justify;">
　　表 3 显示了边缘覆盖率和语句覆盖率的结果。具体而言，我们使用 V1 作为基线，并通过四个指标来评估其他三个 LLMIF 变体的改进情况：边缘覆盖率、语句覆盖率、加速（变体达到基线边缘覆盖率的速度），以及概率（变体在十轮测试中覆盖率优于基线的概率）。</p>

<center>

![alt text](image-7.png)
</center>

<p style="text-align: justify;">
　　结果显示，所有提取的协议信息在覆盖率提升方面发挥了关键作用。具体而言，与 V2 相比，我们评估了提取的有趣值的影响。通过提高 8.61% 的边缘覆盖率和 7.31% 的代码覆盖率，我们表明包含有趣值的测试用例能够有效地探索协议栈，特别是错误处理逻辑和设备功能逻辑。例如，利用 LLM 提取的步态模式值 0x01 和 0x03，模糊测试工具可以生成有意义的步饱和消息，从而分别探索增加和减少饱和属性值的功能逻辑。</p>

<p style="text-align: justify;">
　　通过比较 V2 和 V3，我们评估了消息格式和消息头知识的影响。结果表明，这些知识将边缘覆盖率和语句覆盖率提高了 17.35% 和 15.67%。这些知识在两个方面对变异过程产生了好处。一方面，我们的变异操作符保持生成的测试用例的消息格式，因此它们能够成功通过格式检查并避免被过滤。另一方面，这些操作符变异关键的位和字节，并生成在合法场景中少见的大量测试用例，例如具有反向方向位的集群消息。</p>

<p style="text-align: justify;">
　　最后，我们将 V3 与 V4 进行比较，以评估消息依赖性的影响。结果显示，边缘覆盖率和语句覆盖率分别提高了 9.82% 和 12.75%。这种改善在于许多代码分支依赖于设备属性，而生成的测试用例可以通过解析消息依赖关系并在分支之前更新设备属性来探索这些分支。例如，仅当组大小大于零时，获取组成员消息的执行才会检查组表中的组条目。通过解析“添加组”消息和“获取组成员”消息之间的消息依赖关系，具有消息序列 [添加组，获取组成员] 的测试用例可以有效激活条目检查的分支。</p>

<p style="text-align: justify;">
　　<b>回答 Q2</b>：提取的协议信息增强了模糊测试工具的种子生成、变异和有趣案例丰富能力，分别提高了 8.61%、17.34% 和 9.82% 的代码覆盖率。</p>

##### 现实世界的漏洞


<p style="text-align: justify;">
　　我们评估了漏洞识别的有效性。对于每个测试设备，我们进行了 24 小时的模糊测试，并检查了收集到的崩溃案例。结果如表 2 所示。具体而言，LLMIF 成功地报告了五个设备上的 11 个漏洞，其中包括三个已知漏洞和八个零日漏洞，而基线工具仅识别出一个零日漏洞。所有零日漏洞均已报告，其中五个已确认，三个正在审查中。这些漏洞的总结在表 4 中列出，以下是它们的详细信息。</p>

![alt text](image-8.png)

<p style="text-align: justify;">
　　<b>漏洞 1、2 和 3。</b>LLMIF 成功识别了设备 D1 上的三个已知漏洞（CVE-2020-27890、CVE-2020-27891、CVE-2020-27892）。具体而言，通过生成格式不正确的消息有效载荷，模糊测试工具触发设备错误分配内存，最终导致崩溃。对于基线工具，Z-FUZZER 成功识别了所有这些漏洞，而 BOOFUZZ 错过了 CVE-2020-27890。与之相比，我们发现可以触发这些漏洞的不同消息类型。例如，除了 Read Reporting Configuration Response 消息外，还可以使用 Write Attributes Response 消息来触发该漏洞。</p>

<p style="text-align: justify;">
　　<b>漏洞 4 和 5。</b>我们进一步发现了设备 D1 上的两个未知漏洞。具体而言，当头部中的 Disable Default Response 位设置为 0 时，即需要响应，便会触发这两个漏洞。结果，该设备在生成响应并准备传输时崩溃。此外，所有基线模糊测试工具均未识别这两个漏洞，因为它们既不知道相应的消息格式，也不知道头部位。 </p>

<p style="text-align: justify;">
　　<b>漏洞 6 和 7。</b>我们在设备 D2 上发现了两个漏洞，这与 AddScene 和 EnhanceAddScene 消息有关。具体而言，这两条消息的有效载荷中包含一个字符串字段“SceneName”。通过我们的类型感知变异操作符，特别是可疑长度，LLMIF 将表示字符串长度的第一个字节更改为一个较大的值。因此，当目标设备解析长度字节时，会触发字节溢出，导致设备崩溃。没有基线方法识别出这两个漏洞，因为它们错过了消息格式。 </p>

<p style="text-align: justify;">
　　<b>漏洞 8。</b>我们在设备 D4 和 D11 上发现了一个通过消息序列触发的漏洞。具体而言，设备首先接受一个具有危险字段值的 AddGroup 消息：GroupID=0x0000。此消息将设备置于危险状态。然后，我们的模糊测试工具使用 GetGroupMembership 扩展测试用例，该消息用于查询具有名为“GroupCount”的字段的组列表。我们发现 GroupCount 字段可以任意控制返回组列表的长度。例如，如果 groupCount 字段等于 3，目标设备将返回表示三个 GroupID 的 6 个字节。令人惊讶的是，所有返回的 GroupID 均为 0x0000。因此，通过将 GroupCount 字段设置为相对较大的数字，例如 0xA0，目标设备会尝试返回一个长的组列表，并且大量字节会溢出传输缓冲区，从而导致设备崩溃。没有基线模糊测试工具识别出该漏洞，因为缺乏对危险字段值和消息依赖关系的知识。 </p>

<p style="text-align: justify;">
　　<b>漏洞 9。</b>此漏洞存在于设备 D7 上。具体而言，消息有效载荷有两个字段：GroupCount（uint8）和 GroupList（Array[uint16]）。当 GroupCount 大于列表中的 GroupID 数量时，设备会崩溃。通过在 GroupCount 字段上应用极值变异操作符，我们的模糊测试工具成功触发了该漏洞。CHATAFL 也报告了此漏洞。 </p>

<p style="text-align: justify;">
　　<b>漏洞 10。</b>最后，我们在设备 D7 上发现了一个漏洞，该漏洞由一个格式不正确的消息头触发。具体而言，通过将消息头中的消息标识符字段变异为一个不存在的消息标识符 0x13，设备停止工作。更糟糕的是，它变成了砖头，即使我们按下工厂重置按钮并重启电源，也无法再使用。由于缺乏对消息头的知识，所有基线工具均未报告此漏洞。</p>

<p style="text-align: justify;">
　　<b>问题 Q3 的回答</b> LLMIF 在漏洞识别方面表现出色，成功发现了三项已知漏洞和八项未知漏洞。其中，八项未知漏洞中有七项（87.5%）并未被基线模糊测试工具报告。</p>

## 6. 讨论
<p style="text-align: justify;">
　　<b>网络协议模糊测试中的大语言模型</b>：chatAFL [6] 是首个将大语言模型应用于网络协议模糊测试的工作。然而，LLMIF 在代码覆盖率和漏洞识别方面优于 chatAFL，原因如下：</p>

* (1) 规范增强的提示方法驱动 LLM。LLMIF 使用背景增强提示方法（第 3.2 节），以引导通用大语言模型分析规范内容。与直接通过少量示例学习提示方法驱动通用大语言模型的 chatAFL 相比，LLMIF 成功解决了 LLM 在领域知识不足的问题，并实现了精确的协议信息提取。
* (2) 先进的模糊测试算法用于指导各个模糊测试阶段。LLMIF 利用 LLM 的输出（即提取的协议信息）来指导种子生成、种子变异和测试用例丰富等阶段。此外，LLMIF 利用 LLM 推理设备响应并指导测试用例优先级的确定。与仅利用 LLM 指导两个阶段（种子变异和测试用例丰富）的 chatAFL 相比，LLMIF 实现了更广泛的四个阶段覆盖，显著提高了代码覆盖率（第 5.3 节）。

<p style="text-align: justify;">
　　<b>LLMIF 在其他物联网协议中的通用性</b>：在本文中，我们主要以 Zigbee 作为目标协议。然而，LLMIF 可以扩展到 Zigbee 之外的其他物联网协议进行模糊测试。具体而言，用户只需执行两个步骤，即更新输入规范和更换硬件无线电。为证明 LLMIF 的通用性，我们以 Z-Wave 协议为目标设计了一个案例研究。更多细节请参见我们的补充材料 [15]。</p>
<p style="text-align: justify;">
　　更新输入规范：LLMIF 依赖于协议规范来增强 LLM 并提取关键的消息信息。因此，用户需要提供详细描述所模糊测试协议消息的规范作为输入，例如 Z-Wave 命令类 [43]。通过我们的文档切片和背景增强提示方法（第 3.2 节），LLMIF 将提取精确的协议信息（如消息格式和消息依赖关系），并利用这些信息指导模糊测试过程。</p>
<p style="text-align: justify;">
　　更换硬件无线电：要对特定物联网协议的真实设备进行模糊测试，必须有一个硬件无线电来在特定无线信道中发送测试用例并接收响应。用户需要准备相应的硬件（例如，用于 Zigbee 的 CC2530），下载商业协议栈（例如，ZStack），并实现与 LLMIF 交互的驱动程序。驱动程序的实现依赖于商业协议栈的开发环境，我们为 Z-Stack 实现的驱动程序提供了一个示例（第 4.6 节）</p>

## 7. 相关工作
<p style="text-align: justify;">
　　<b>格式感知的物联网模糊测试</b>：格式感知的模糊测试工具基于良构的消息模板生成消息 [3]，[4]，[5]，[10]，[42]，[44]。具体而言，[42] 提出了一个网络协议模糊测试框架 BooFuzz。该工具以消息格式描述和有趣值集合为输入，自动生成测试用例，监控目标状态并记录可疑案例。[4] 基于 BooFuzz 设计了一款模糊测试工具 Z-Fuzzer，旨在对 Zigbee 协议进行模糊测试，并使用代码覆盖率作为反馈来指导模糊测试过程。[5] 手动提取了 22 种集群消息格式和有趣字段值（例如，属性 ID），并开发了 BeeHive，该工具生成测试用例以枚举这些消息和字段值。[10] 依赖于开源协议库中记录的消息格式来生成测试用例。所有这些方法都需要大量人力来构建和维护消息格式，这既劳动密集又容易出错。[3] 和 [44] 提出了使用手机应用程序和 API 通过供应商平台控制设备来构建消息格式的方法。然而，它们主要集中在推断平台级消息格式（例如，Restful API 消息），仅涵盖设备直接使用的底层协议的小部分消息格式，例如 Zigbee。</p>

<p style="text-align: justify;">
　　与上述工作相比，我们提出利用 LLM 来解决格式感知物联网模糊测试的主要挑战。仅凭规范文档作为输入，我们的方法能够自动构建高精度的消息格式，同时避免了大量人力投入。除了消息格式的知识，我们的方法还提取了有用的协议信息，例如有趣值和消息依赖关系，这有利于模糊测试过程，而之前的工作对此有所忽略。特别是，我们的评估覆盖了大多数 Zigbee 模糊测试工具 [4]，[5]，[42]，评估结果表明我们的方法在代码覆盖率和漏洞识别方面优于它们。由于某些模糊测试工具 [10] 不是开源的，我们无法评估它们的性能。</p>

<p style="text-align: justify;">
　　<b>基于 LLM 的模糊测试：</b>受到 LLM 在各种自然语言处理任务中显著成功的启发，研究人员一直在探索 LLM 在不同领域的潜力，包括模糊测试 [6]，[45]，[46]，[47]，[48]。具体而言，[45] 提出了 CODAMOSA，利用 LLM 自动生成模糊测试 Python 模块的测试用例。[46] 使用 LLM 生成模糊测试深度学习软件库的测试用例。[48] 提出了 Fuzz4All，该工具以示例代码作为输入，生成稍有不同的代码片段作为测试用例。chatFuzz [47] 不是直接要求 LLM 生成测试用例，而是要求 LLM 修改人类编写的测试用例以用于变异。与我们论文最相关的工作是 chatAFL [6]，它使用 LLM 对网络协议进行模糊测试。通过利用 LLM 对目标协议的理解，chatAFL 让 LLM 构建消息格式并丰富种子。所有提到的基于 LLM 的模糊测试工具都建立在 LLM 拥有足够领域知识的假设上，例如 Python 语法和协议细节，从而可以轻松适应模糊测试任务。相反，我们的工作发起了一个 Zigbee 模糊测试的案例研究，表明这一假设并不成立。此外，我们提出了一种 LLM 增强方法，为 LLM 提供规范内容，评估结果表明增强后的 LLM 可以有效指导各种模糊测试阶段。</p>

<p style="text-align: justify;">
　　<b>增强语言模型</b>：LLM 默认具备广泛主题的通用知识。然而，[24]，[25] 显示 LLM 可能没有获得足够的特定领域知识。原因多种多样，例如，知识偏见存在于更受欢迎或广泛讨论的主题（例如，Python 编程），而非常特定领域的主题（例如，Zigbee 协议）通常会被低估。因此，提出了一系列工作来用领域知识增强语言模型 [31]，[32]，[49]，[50]，[51]，[52]。具体而言，[31]，[32]，[49] 采用神经检索器从知识库（例如，维基百科）获取与任务相关的信息，并对语言模型进行微调。[50]，[51]，[52] 则教导 LLM 调用领域工具生成答案，例如，编写 SQL 查询数据库。我们的工作遵循前者的范式，即检索领域知识并增强 LLM。与之前的工作不同，我们使用文档分析来检索领域知识，而不是训练神经网络。此外，我们使用提示工程来输入 LLM，从而免去了微调的成本。</p>

## 8. 总结
<p style="text-align: justify;">
　　对物联网协议（例如，Zigbee）的模糊测试面临着一些关键挑战，包括模糊的消息格式、未解决的消息依赖关系以及缺乏测试用例评估。本文展示了协议规范中包含丰富的消息描述，这些描述可以用来解决这些限制并指导模糊测试过程。为了自动化规范分析，我们进一步增强了大语言模型（LLM），利用规范内容驱动其回答与协议相关的问题。最后，我们提出了一种模糊测试算法 LLMIF，该算法将增强后的 LLM 融入 Zigbee 模糊测试中。评估结果表明，在 LLM 的指导下，我们的方法将消息覆盖率提高了 55.2%，并实现了 53.9% 的代码覆盖率提升。此外，LLMIF 在真实的 Zigbee 设备上发现了 11 个漏洞（包括 8 个零日漏洞），而基线工具仅发现了一个零日漏洞。</p>

